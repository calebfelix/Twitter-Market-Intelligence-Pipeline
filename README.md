# Twitter Market Intelligence Pipeline

A Python-based data pipeline that scrapes recent market-related tweets from Twitter/X (without using the official API), processes the data, and prepares it for downstream analysis.

This project is designed as a **proof-of-concept** to demonstrate pipeline architecture, defensive scraping, and real-world failure handling.

---

## ðŸ“Œ Features

- Scrapes recent tweets for market-related hashtags:
  - `#nifty50`
  - `#sensex`
  - `#banknifty`
  - `#intraday`
- Simulates human browsing behavior using Selenium
- Filters tweets from the last 24 hours
- Removes duplicates
- Extracts structured fields:
  - Username
  - Timestamp
  - Content
  - Likes
  - Hashtags
  - Mentions
- Detects Twitter/X login walls and exits gracefully
- Modular, readable project structure

---

## ðŸ—ï¸ Project Structure

```
twitter-market-intel/
â”œâ”€â”€ main.py
â”œâ”€â”€ run.sh
â”œâ”€â”€ scraper/
â”‚   â”œâ”€â”€ browser.py
â”‚   â””â”€â”€ twitter_scraper.py
â”œâ”€â”€ processing/
â”œâ”€â”€ analysis/
â”œâ”€â”€ storage/
â”œâ”€â”€ logs/
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

---

## âš™ï¸ Requirements

- Python **3.11** (recommended)
- Google Chrome (installed locally)
- Linux environment

> âš ï¸ Python 3.13 + Selenium may be unstable. Python 3.11 is recommended for reliability.

---

## ðŸš€ Setup & Run

### 1ï¸âƒ£ Create and activate virtual environment

```bash
python3 -m venv venv
source venv/bin/activate
```

### 2ï¸âƒ£ Install dependencies

```bash
pip install -r requirements.txt
```

### 3ï¸âƒ£ Run the pipeline

```bash
python main.py 
```

Or using the helper script:

```bash
chmod +x run.sh
./run.sh
```

---

## âš ï¸ Twitter/X Access Limitation

Twitter/X employs anti-bot protections that may present a **login wall**, especially in headless or unauthenticated sessions.

This pipeline:
- **Detects login walls**
- **Fails fast with a clear error**
- Avoids infinite waits or silent failures

> Authentication via session reuse or official APIs would be required for a production-grade system.  
> This was intentionally not implemented to stay within ethical and assignment constraints.

---

## ðŸ§  Design Decisions

- **No Twitter API usage** (as per assignment requirement)
- **No automated login or credential handling**
- Human-like scrolling with randomized delays
- Defensive error handling for unstable external dependencies
- Modular pipeline design for extensibility

---

## ðŸ“ˆ Future Improvements

- Authenticated scraping via session reuse (cookie-based)
- Concurrency across hashtags
- Retry and backoff strategies
- Persistent storage (Parquet / database)
- Sentiment scoring and signal aggregation


## ðŸ‘¤ Author

Caleb Felix
